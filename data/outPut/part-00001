(n,,1)
(```scala,1)
(_),1)
(",1)
(配置Spark客户端，并启动spark,1)
(搭建hadoop集群,1)
(is,1)
(x,1)
(YARN/HDFS配置文件参考：conf/hadoop目录,1)
(解压spark安装包,1)
(bin/spark-shell,1)
(until,1)
(0,1)
(4.0,1)
(sc.parallelize(1,1)
(aura.cn,1)
($,1)
(下载spark安装包,1)
((x*x,1)
(```bash,1)
(cluster：bin/spark-shell,1)
(cluster,1)
(y*y,1)
(将spark-shell运行在yarn,1)
(在命令行提示符下拷贝以下代码并查看执行结果,1)
(1),1)
(启动spark,1)
(println("Pi,1)
(}.reduce(_,1)
(Training,1)
(roughly,1)
(Hadoop,1)
(),1)
(<=,1)
(Spark,1)
(/,1)
(分布式运行Spark方法,1)
(server,1)
(client模式：bin/spark-shell,1)
(sbin/start-history-server.sh,1)
(import,1)
(if,1)
(i,1)
(y,1)
(sparktraining,1)
(server:,1)
(Examples,1)
(Spark客户端配置文件参考：conf/spark目录,1)
(client,1)
(in,1)
(else,1)
(for,1)
(tasks).map,1)
(=>,1)
(100000,1)
({,1)
(scala.math.random,1)
(本地运行Spark方法,1)
(client或cluster模式,1)
(10,1)
(进入spark解压目录下，运行：,1)
